{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a text classifier model with fastai\n",
    "- this notebook assumes you have already run text_model_training.ipynb notebook\n",
    "- In this notebook, the IMDB dataset is ingested\n",
    "- the first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to control whether direct TDL or DataBlocks definition used \n",
    "tdl = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = 'mar3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the dataset\n",
    "- define the path for the dataset\n",
    "- create a TextDataLoaders object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.25 ms, sys: 0 ns, total: 5.25 ms\n",
      "Wall time: 6.57 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#7) [Path('/storage/data/imdb/README'),Path('/storage/data/imdb/tmp_lm'),Path('/storage/data/imdb/imdb.vocab'),Path('/storage/data/imdb/tmp_clas'),Path('/storage/data/imdb/test'),Path('/storage/data/imdb/train'),Path('/storage/data/imdb/unsup')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create dataloaders object\n",
    "'''dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=16)\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)'''\n",
    "# LSTM have multiple dropout probabilities for different things. Once you set them, this drop_mult property scales all of them. So you can change all dropout probabilities simultaneously using this, keeping their relative size\n",
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define TextDataLoaders object\n",
    "dls_clas = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n├── test\\n│   ├── neg\\n│   └── pos\\n├── tmp_clas\\n├── tmp_lm\\n├── train\\n│   ├── neg\\n│   └── pos\\n└── unsup\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory structure of the IMDB curated dataset\n",
    "'''\n",
    "├── test\n",
    "│   ├── neg\n",
    "│   └── pos\n",
    "├── tmp_clas\n",
    "├── tmp_lm\n",
    "├── train\n",
    "│   ├── neg\n",
    "│   └── pos\n",
    "└── unsup\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/imdb')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_path is:  /storage/data/imdb\n"
     ]
    }
   ],
   "source": [
    "# save the current path\n",
    "keep_path = path\n",
    "print(\"keep_path is: \",str(keep_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 5.05 s, total: 8.31 s\n",
      "Wall time: 2.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define a text_classifier_learner object\n",
    "learn_clas = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
    "                                metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/imdb')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path('/storage/data/imdb')\n",
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 472 µs, total: 472 µs\n",
      "Wall time: 68.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set the path to the location of the encoder\n",
    "learn_clas.path = Path('/notebooks/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoder that was saved when the language model was trained\n",
    "learn_clas = learn_clas.load_encoder('ft_'+modifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/notebooks/temp')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path back to the original path\n",
    "learn_clas.path = keep_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/imdb')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ch 10 style Path('/storage/data/imdb')\n",
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.410315</td>\n",
       "      <td>0.274882</td>\n",
       "      <td>0.887360</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 55.8 s, total: 3min 21s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fine tune the model\n",
    "learn_clas.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3345]), torch.Size([64]), 390)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = first(dls_clas.train)\n",
    "x.shape, y.shape, len(dls_clas.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxmaj this movie was recently released on xxup dvd in the xxup us and i finally got the chance to see this hard - to - find gem . xxmaj it even came with original theatrical previews of other xxmaj italian horror classics like \" xxunk \" and \" beyond xxup the xxup darkness \" . xxmaj unfortunately , the previews were the best thing about this movie . \\n\\n \" zombi 3 \" in a bizarre way is actually linked to the infamous xxmaj lucio xxmaj fulci \" zombie \" franchise which began in 1979 . xxmaj similarly compared to \" zombie \" , \" zombi 3 \" consists of a threadbare plot and a handful of extremely bad actors that keeps this ' horror ' trash barely afloat . xxmaj the gore is nearly non - existent ( unless one is frightened of people running around with</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos i thought that xxup rotj was clearly the best out of the three xxmaj star xxmaj wars movies . i find it surprising that xxup rotj is considered the weakest installment in the xxmaj trilogy by many who have voted . xxmaj to me it seemed like xxup rotj was the best because it had the most profound plot , the most suspense , surprises , most xxunk the ending ) and definitely the most episodic movie . i personally like the xxmaj empire xxmaj strikes xxmaj back a lot also but i think it is slightly less good than than xxup rotj since it was slower - moving , was not as episodic , and i just did not feel as much suspense or emotion as i did with the third movie . \\n\\n xxmaj it also seems like to me that after reading these surprising reviews that</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos xxunk ) is the developing world 's answer to xxmaj silence of the xxmaj lambs . xxmaj where ` silence ' terrorized our peace of mind , ` citizen ' exhausts and saddens us instead . xxmaj this dramatization of the xxmaj chikatilo case translates rather well , thanks to a xxmaj westernized friendship between two xxmaj rostov cops who become equals . \\n\\n citizenx may also argue against ( ! ) the death penalty far better than xxmaj kevin xxmaj spacey 's xxmaj the xxmaj life of xxmaj david xxmaj xxunk ) . \\n\\n xxmaj humans are xxmaj machiavellian mammals , under which lie limbic brains ( lizard - logic ) . xxmaj why did two kids , who knew better , stone to death a toddler they kidnapped ? xxmaj why do bloodthirsty women yell ` li - xxunk ' at acts of xxup obscene terrorism ?</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos 8 xxmaj simple xxmaj rules for xxmaj dating xxmaj my xxmaj teenage xxmaj daughter had an auspicious start . xxmaj the supremely - talented xxmaj tom xxmaj shadyac was involved in the project . xxmaj this meant that the comedy would be nothing less of spectacular , and that 's exactly what happened : the show remains one of the freshest , funniest , wittiest shows made in a very long time . xxmaj every line , facial expression , casting choice , scene , all wreaked of perfection . xxmaj there was not one episode after which i thought , \" man that was n't as good as the rest \" . xxmaj each one was a standout . xxmaj again , this is the kind of perfectionism that we 've come to expect from xxmaj tom . xxmaj for those who do n't know , xxmaj tom</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos xxmaj warning : xxmaj spoilers xxmaj galore ! \\n\\n xxmaj tim xxmaj burton remaking this sui generis movie is about as sensible as remaking xxmaj psycho - oh , that 's right , some idiot already did that - i rest my case . \\n\\n xxmaj movie opens with xxunk blundering a simulation , proving he 's not that smart from the outset . xxmaj marky xxmaj mark appears in shot without his characteristic underpants showing , then is turned down by a plain woman who prefers the touch of chimpanzees . \\n\\n xxmaj the perfunctory establishing shot of the space station orbiting xxmaj saturn for no apparent reason , interior of ship a - bustle with genetic experiments on apes . xxmaj must we travel xxunk million kilometers to xxmaj saturn to conduct these experiments ? xxmaj the special effects team decrees it . \\n\\n xxmaj marky 's</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos xxmaj it has said that xxmaj the xxmaj movies and xxmaj baseball both thrived during xxmaj the xxmaj great xxmaj depression . xxmaj it appears that the grim realities of a xxmaj nation caught up in the aftermath of this xxmaj economic xxmaj disaster created a need for occasional relief for the populace . a temporary escape could be found in the on going soap opera that is xxmaj baseball . \\n\\n xxmaj likewise , an occasional excursion of 2 or 3 hours into the darkened xxunk of the xxmaj cinema . xxmaj the presence of a xxmaj radio in just about everyone 's house hold kept xxmaj depression xxmaj era xxmaj america at once attuned to xxmaj world 's xxmaj events and provided many a xxmaj drama and ( especially ) xxmaj comedy xxmaj shows for a pleasant interlude from harsh reality . \\n\\n xxmaj the literature of</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos xxmaj how strange the human mind is ; this center of activity wherein perceptions of reality are formed and stored , and in which one 's view of the world hinges on the finely tuned functioning of the brain , this most delicate and intricate processor of all things sensory . xxmaj and how much do we really know of it 's inner - workings , of it 's depth or capacity ? xxmaj what is it in the mind that allows us to discern between reality and a dream ? xxmaj or can we ? xxmaj perhaps our sense of reality is no more than an impression of what we actually see , like looking at a painting by xxmaj monet , in which the vanilla sky of his vision becomes our reality . xxmaj it 's a concept visited by filmmaker xxmaj cameron xxmaj crowe in his</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xxbos xxmaj the majority of xxmaj stephen xxmaj king 's short stories are little gems , with original ideas that do n't take a long time to develop ; basically lean and mean -- he sets them up quickly in a scarce number of pages , you read 'em , and you 're finished before you know you 've begun . xxmaj they 're like the equivalent of a carton of mcdonald 's fries -- they taste xxmaj really good and you know there 's not much nutritional value in them ( re : from a literary standpoint , they do n't say much about the universal human condition ) , but you 're still gon na scarf 'em down , just do n't be a pig and go for the extra - super - sized portion and fill up on too much grease ( \" too much grease \"</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SequentialRNN (Input shape: ['64 x 3345'])\n",
       "================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "================================================================\n",
       "LSTM                 ['64 x 33 x 1152',   1,852,416  False     \n",
       "________________________________________________________________\n",
       "LSTM                 ['64 x 33 x 1152',   5,317,632  False     \n",
       "________________________________________________________________\n",
       "LSTM                 ['64 x 33 x 400', \"  1,846,400  False     \n",
       "________________________________________________________________\n",
       "RNNDropout           64 x 33 x 400        0          False     \n",
       "________________________________________________________________\n",
       "RNNDropout           64 x 33 x 1152       0          False     \n",
       "________________________________________________________________\n",
       "RNNDropout           64 x 33 x 1152       0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          64 x 1200            2,400      True      \n",
       "________________________________________________________________\n",
       "Dropout              64 x 1200            0          False     \n",
       "________________________________________________________________\n",
       "Linear               64 x 50              60,000     True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 50              0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          64 x 50              100        True      \n",
       "________________________________________________________________\n",
       "Dropout              64 x 50              0          False     \n",
       "________________________________________________________________\n",
       "Linear               64 x 2               100        True      \n",
       "________________________________________________________________\n",
       "\n",
       "Total params: 9,079,048\n",
       "Total trainable params: 62,600\n",
       "Total non-trainable params: 9,016,448\n",
       "\n",
       "Optimizer used: <function Adam at 0x7f380ea7c940>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #4\n",
       "\n",
       "Callbacks:\n",
       "  - ModelResetter\n",
       "  - RNNRegularizer\n",
       "  - ModelToHalf\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback\n",
       "  - MixedPrecision"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%time\\nlearn_clas.freeze_to(-2)\\nlearn_clas.fit_one_cycle(1, 2e-2)\\n'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(1, 2e-2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learn_clas.predict(\"this film shows incredibly bad writing and is a complete disaster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', TensorText(0), TensorText([0.9985, 0.0015]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learn_clas.predict(\"what a terrible film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', TensorText(0), TensorText([0.8799, 0.1201]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/notebooks/temp/models/classifier_single_epoch_mar3c.pth')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the classifier model\n",
    "learn_clas.path = Path('/notebooks/temp')\n",
    "learn_clas.save('classifier_single_epoch_'+modifier+'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
