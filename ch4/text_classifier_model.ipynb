{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a text classifier model with fastai\n",
    "- this notebook assumes you have already run text_model_training.ipynb notebook\n",
    "- In this notebook, the IMDB dataset is ingested\n",
    "- the first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = 'mar3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the dataset\n",
    "- define the path for the dataset\n",
    "- create a TextDataLoaders object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.47 ms, sys: 593 µs, total: 7.06 ms\n",
      "Wall time: 15.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#7) [Path('/storage/data/imdb/README'),Path('/storage/data/imdb/tmp_lm'),Path('/storage/data/imdb/imdb.vocab'),Path('/storage/data/imdb/tmp_clas'),Path('/storage/data/imdb/test'),Path('/storage/data/imdb/train'),Path('/storage/data/imdb/unsup')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create dataloaders object\n",
    "'''dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=16)\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)'''\n",
    "# LSTM have multiple dropout probabilities for different things. Once you set them, this drop_mult property scales all of them. So you can change all dropout probabilities simultaneously using this, keeping their relative size\n",
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=8)\n",
    "# get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
    "dls = TextDataLoaders.from_folder(path, valid = 'test', is_lm=True, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndls_clas = DataBlock(\\n    blocks=(TextBlock.from_folder(path, vocab=dls.vocab),CategoryBlock),\\n    get_y = parent_label,\\n    get_items=partial(get_text_files, folders=['train', 'test']),\\n    splitter=GrandparentSplitter(valid_name='test')\\n).dataloaders(path, path=path, bs=128, seq_len=72)\\n\\n\\n\\nThe independent variable is often referred to as x, and the dependent variable is often referred to as y.\\nHere, we are telling fastai what function to call to create the labels in our dataset: \\nget_y=parent_label parent_label is a function provided by fastai that simply gets the name of the \\nfolder a file is in. Because we put each of our bear images into folders based on the type of bear, \\nthis is going to give us the labels that we need.\\n\\n\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dls definition cribbed from chapter 10\n",
    "# this works\n",
    "'''\n",
    "dls_clas = DataBlock(\n",
    "    blocks=(TextBlock.from_folder(path, vocab=dls.vocab),CategoryBlock),\n",
    "    get_y = parent_label,\n",
    "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
    "    splitter=GrandparentSplitter(valid_name='test')\n",
    ").dataloaders(path, path=path, bs=128, seq_len=72)\n",
    "\n",
    "Partial functions allow us to fix a certain number of arguments of a function and generate a new function\n",
    "\n",
    "The independent variable is often referred to as x, and the dependent variable is often referred to as y.\n",
    "Here, we are telling fastai what function to call to create the labels in our dataset: \n",
    "get_y=parent_label parent_label is a function provided by fastai that simply gets the name of the \n",
    "folder a file is in. Because we put each of our bear images into folders based on the type of bear, \n",
    "this is going to give us the labels that we need.\n",
    "\n",
    "get_items: get_items is completely decoupled from get_x and get_y: it is there to return all your items from \n",
    "the source. You can pass get_x and get_y (or a list of getters) to explain how to get your x and y from the result of \n",
    "get_items and they both default to noop (which is why when get_items return filenames, we don’t pass a get_x)\n",
    "\n",
    "GrandparentSplitter - Split items from the grand parent folder names (train_name and valid_name).\n",
    "\n",
    "seq_len: The LMDataLoader will concatenate all texts (maybe shuffled) in one big stream, \n",
    "split it in bs contiguous sentences, then go through those seq_len at a time.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# details on sequence length meaining\n",
    "\n",
    "bs,sl = 4,3\n",
    "ints = L([0,1,2,3,4],[5,6,7,8,9,10],[11,12,13,14,15,16,17,18],[19,20],[21,22,23],[24]).map(tensor)\n",
    "\n",
    "dl = LMDataLoader(ints, bs=bs, seq_len=sl)\n",
    "test_eq(list(dl),\n",
    "    [[tensor([[0, 1, 2], [6, 7, 8], [12, 13, 14], [18, 19, 20]]),\n",
    "      tensor([[1, 2, 3], [7, 8, 9], [13, 14, 15], [19, 20, 21]])],\n",
    "     [tensor([[3, 4, 5], [ 9, 10, 11], [15, 16, 17], [21, 22, 23]]),\n",
    "      tensor([[4, 5, 6], [10, 11, 12], [16, 17, 18], [22, 23, 24]])]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEFINITION OF DATABLOCK:\n",
    "\n",
    "Generic container to quickly build Datasets and DataLoaders\n",
    "\n",
    "To build a DataBlock you need to give the library four things: the types of your input/labels, \n",
    "and at least two functions: get_items and splitter. You may also need to include get_x and get_y \n",
    "or a more generic list of getters that are applied to the results of get_items.\n",
    "\n",
    "Once those are provided, you automatically get a Datasets or a DataLoaders\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactored definition of dataloader object\n",
    "'''dls = TextDataLoaders.from_df(\n",
    "    df_tok, path=path, \n",
    "    vocab = make_vocab(count),\n",
    "    text_col = 'text',label_col='label')\n",
    "'''\n",
    "\n",
    "dls_clas = TextDataLoaders.from_folder(path=path,\n",
    "    blocks=(TextBlock.from_folder(path, vocab=dls.vocab),CategoryBlock),\n",
    "#path, vocab=dls.vocab,     \n",
    "#    text_col= 'text', \n",
    "#   label_col='label',\n",
    "    get_y = parent_label,\n",
    "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
    "    splitter=GrandparentSplitter(valid_name='test'),\n",
    "#    get_items=partial(get_text_files, folders=['train', 'test']),\n",
    "#    splitter=GrandparentSplitter(valid_name='test'), \n",
    "    bs=128, seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/imdb')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_path = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/imdb')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ch 10 style Path('/storage/data/imdb')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 s, sys: 4.07 s, total: 6.8 s\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define a text_classifier_learner object\n",
    "learn_clas = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
    "                                metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/imdb')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path('/storage/data/imdb')\n",
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 11 µs, total: 35 µs\n",
      "Wall time: 39.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set the path to the location of the encoder\n",
    "learn_clas.path = Path('/notebooks/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoder that was saved when the language model was trained\n",
    "learn_clas = learn_clas.load_encoder('ft_'+modifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas.path = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/imdb')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ch 10 style Path('/storage/data/imdb')\n",
    "learn_clas.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.416182</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.8/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 30.5 s, total: 1min 37s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn_clas.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn_clas.predict(\"this film shows incredibly bad writing and is a complete disaster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', TensorText(0), TensorText([9.9998e-01, 2.0704e-05]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learn_clas.predict(\"what a terrible film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', TensorText(0), TensorText([9.9956e-01, 4.4422e-04]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/notebooks/temp/models/classifier_single_epoch_mar3b.pth')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_clas.save('classifier_single_epoch_'+modifier+'b')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
